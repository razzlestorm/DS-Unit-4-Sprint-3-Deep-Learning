{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on SageMaker, Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe the components of an autoencoder\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - RNNs\n",
    "\n",
    "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=723812,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (8982, 200)\n",
      "X_test shape: (2246, 200)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "batch_size = 46\n",
    "max_features = len(word_index.values())\n",
    "maxlen = 200\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features+1, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(max_features, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/3\n",
      "8982/8982 [==============================] - 166s 18ms/sample - loss: 4.5282 - acc: 0.2751 - val_loss: 2.5819 - val_acc: 0.3664\n",
      "Epoch 2/3\n",
      "8982/8982 [==============================] - 164s 18ms/sample - loss: 2.4843 - acc: 0.3506 - val_loss: 2.4084 - val_acc: 0.3664\n",
      "Epoch 3/3\n",
      "8982/8982 [==============================] - 165s 18ms/sample - loss: 2.4520 - acc: 0.3506 - val_loss: 2.3912 - val_acc: 0.3664\n",
      "2246/2246 [==============================] - 5s 2ms/sample - loss: 2.3912 - acc: 0.3664\n",
      "Test score: 2.391159341681354\n",
      "Test accuracy: 0.3664292\n"
     ]
    }
   ],
   "source": [
    "# You should only run this cell once your model has been properly configured\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
    "\n",
    "The pad_sequences method is a keras preprocessing method that makes sure all of the sequences in a dataset are the same length. It lengthens shorter sequences, and can set a max length on longer sequences. This is done to ensure consistency.\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "\n",
    "RNNs aren't great at remembering long-term dependencies, so LSTMs add memory gates so they can use earlier weights.\n",
    "\n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "\n",
    "LSTMs can be used for Time Series data, as well as text that is treated like a time series. They are well-suited to this because they remember weights from earlier times (so they can find patterns in year-long data). This allows them to create/remember context! LTSMs can then be used to generate text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_images_download\n",
      "  Downloading google_images_download-2.8.0.tar.gz (14 kB)\n",
      "Requirement already satisfied: selenium in d:\\csfiles\\lambda\\git\\deep_learning\\venv\\lib\\site-packages (from google_images_download) (3.141.0)\n",
      "Requirement already satisfied: urllib3 in d:\\csfiles\\lambda\\git\\deep_learning\\venv\\lib\\site-packages (from selenium->google_images_download) (1.25.8)\n",
      "Building wheels for collected packages: google-images-download\n",
      "  Building wheel for google-images-download (setup.py): started\n",
      "  Building wheel for google-images-download (setup.py): finished with status 'done'\n",
      "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14555 sha256=6f29882ad50bd3f85838f478fc3c4740b1babe2611b8125a19ec080ce4d27306\n",
      "  Stored in directory: c:\\users\\jwill\\appdata\\local\\pip\\cache\\wheels\\e3\\98\\42\\0d3a76d46cd5a6659afb2f5612d4908ca42d34060973d46727\n",
      "Successfully built google-images-download\n",
      "Installing collected packages: google-images-download\n",
      "Successfully installed google-images-download-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = frog\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 5 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\": \"frog\", \"limit\": 5, \"print_urls\": True}\n",
    "absolute_image_paths = response.download(arguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goals* \n",
    "- Check for fish or other labels\n",
    "- Create a matplotlib visualizations of the images and your prediction as the visualization label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [],
   "source": [
    "# You've got something to do in this cell. ;)\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def process_img_path(img_path):\n",
    "    return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "    \"\"\" Scans image for Frogs\n",
    "    \n",
    "    Should return a boolean (True/False) if a frog is in the image.\n",
    "    \n",
    "    Inputs:\n",
    "    ---------\n",
    "    img:  Precrossed image ready for prediction. The `process_img_path`             function should already be applied to the image. \n",
    "    \n",
    "    Returns: \n",
    "    ---------\n",
    "    frogs (boolean):  TRUE or FALSE - There are frogs in the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=3)[0]\n",
    "    print(results)\n",
    "    if 'frog' in results[0][1] and results[0][2] > 0.25:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n01644373', 'tree_frog', 0.93838465), ('n02259212', 'leafhopper', 0.01597091), ('n01693334', 'green_lizard', 0.014538255)]\n",
      "True\n",
      "[('n01644900', 'tailed_frog', 0.32799807), ('n01641577', 'bullfrog', 0.22553708), ('n01644373', 'tree_frog', 0.16573411)]\n",
      "True\n",
      "[('n02077923', 'sea_lion', 0.9197687), ('n02442845', 'mink', 0.021568758), ('n02444819', 'otter', 0.016232025)]\n",
      "False\n",
      "[('n01644373', 'tree_frog', 0.4067175), ('n01693334', 'green_lizard', 0.16490583), ('n01682714', 'American_chameleon', 0.11815245)]\n",
      "True\n",
      "[('n01644373', 'tree_frog', 0.9423204), ('n01644900', 'tailed_frog', 0.056342434), ('n01641577', 'bullfrog', 0.00067995396)]\n",
      "True\n",
      "[('n01644373', 'tree_frog', 0.992164), ('n02169497', 'leaf_beetle', 0.0034639419), ('n01644900', 'tailed_frog', 0.0028726757)]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Added an image of an otter just to make sure it's working\n",
    "\n",
    "imagelist = glob.glob('downloads/frog/*.jpg') + glob.glob('downloads/frog/*.png')\n",
    "for x in imagelist:\n",
    "    print(img_contains_frog(process_img_path(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stretch Goal: Displaying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
    "\n",
    "__*Your Answer:*__  \n",
    "Autoencoders can be used for denoising images, to make the images smoother, or to enhance a certain part of the image beyond what has previously been capable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "**- What do you consider your strongest area, as a Data Scientist?**\n",
    "Natural Language Processing, given that I've actually done a few projects with it. I still have a BUNCH more to learn though!\n",
    "\n",
    "\n",
    "**- What area of Data Science would you most like to learn more about, and why?**\n",
    "NLP again. I believe language isn't going to be going away anytime soon, and in an era of misinformation, being able to both communicate effectively and detect misinformation is essential.\n",
    "\n",
    "\n",
    "**- Where do you think Data Science will be in 5 years?**\n",
    "All I can predict is that the techniques we have will be better, we'll be able to train NNs faster/easier. Better computer vision recognition of things will probably happen.\n",
    "\n",
    "\n",
    "**- What are the threats posed by AI to our society?**\n",
    "Unemployment, run-away biases, privacy\n",
    "\n",
    "\n",
    "**- How do you think we can counteract those threats?**\n",
    "For unemployment: UBI, taxes, regulation!\n",
    "For bias: Creating proper models and making sure datasets are as unbiased as possible\n",
    "For privacy: I... don't know that we can counteract it, really.\n",
    "\n",
    "\n",
    "**- Do you think achieving General Artifical Intelligence is ever possible?**\n",
    "Yes, but... not for a long time, due to processing power and the complexity of a solution\n",
    "\n",
    "\n",
    "\n",
    "A few sentences per answer is fine - only elaborate if time allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
